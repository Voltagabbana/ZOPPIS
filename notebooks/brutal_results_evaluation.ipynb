{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23/12/2024\n",
    "\n",
    "In questo notebook provo a vedere se si può tentare un approccio AI per la valutazione dei candidati (che possa sostituire il recruiter per la valutazione) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizzo Google gemini api https://ai.google.dev/gemini-api/docs/quickstart?lang=python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/get-started/python.ipynb (tutorial colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup (and experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_markdown(text):\n",
    "    text = text.replace(\"•\", \"  *\")\n",
    "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.environ.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plain text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Prevedere con precisione i lavori del futuro è impossibile, ma possiamo analizzare le tendenze attuali per identificare settori e competenze probabilmente richiesti.  Questi lavori saranno influenzati da diversi fattori, tra cui l'automazione, l'intelligenza artificiale, la sostenibilità e la globalizzazione.\n",
       "> \n",
       "> **Settori in crescita:**\n",
       "> \n",
       "> * **Tecnologie dell'informazione e della comunicazione (ICT):**  Sviluppatori di software e applicazioni, specialisti in cybersecurity, ingegneri del cloud, analisti di dati, esperti di intelligenza artificiale (AI) e machine learning (ML), specialisti in blockchain, esperti di realtà virtuale (VR) e aumentata (AR).  La domanda per queste competenze è già alta e continuerà ad aumentare.\n",
       "> \n",
       "> * **Scienze biologiche e mediche:** Bioingegneri, bioinformatici, ricercatori medici, genetisti, tecnici di laboratorio specializzati in biotecnologie, esperti di medicina personalizzata.  L'innovazione nel settore sanitario e la crescente longevità della popolazione alimenteranno la richiesta di questi profili.\n",
       "> \n",
       "> * **Energia rinnovabile e sostenibilità:**  Ingegneri ambientali, esperti di energie rinnovabili (solare, eolica, idroelettrica, geotermica), specialisti in efficienza energetica, esperti di gestione dei rifiuti e di economia circolare. La transizione verso un'economia più sostenibile crea un bisogno crescente di queste figure.\n",
       "> \n",
       "> * **Data science e analisi dei dati:** Data scientist, data analyst, business intelligence analyst. L'enorme quantità di dati generati richiede professionisti capaci di analizzarli ed estrarre informazioni utili per le aziende e la ricerca.\n",
       "> \n",
       "> * **Robotica e automazione:**  Ingegneri robotici, tecnici di manutenzione e riparazione di robot, specialisti in automazione industriale. L'automazione sta trasformando molti settori, creando nuove necessità di competenze specializzate.\n",
       "> \n",
       "> * **Industria creativa e digitale:**  Designer di UX/UI, sviluppatori di videogiochi, content creator, esperti di marketing digitale, influencer. La comunicazione e l'intrattenimento digitale sono settori in continua espansione.\n",
       "> \n",
       "> \n",
       "> **Competenze trasversali sempre più richieste:**\n",
       "> \n",
       "> * **Problem-solving e pensiero critico:** capacità di analizzare situazioni complesse e trovare soluzioni innovative.\n",
       "> * **Adattamento e flessibilità:**  capacità di apprendere continuamente nuove competenze e adattarsi ai cambiamenti rapidi del mercato del lavoro.\n",
       "> * **Collaborazione e comunicazione:**  capacità di lavorare efficacemente in team e comunicare in modo chiaro ed efficace.\n",
       "> * **Creatività e innovazione:** capacità di pensare fuori dagli schemi e generare nuove idee.\n",
       "> * **Digital literacy:**  conoscenza e capacità di utilizzo delle tecnologie digitali.\n",
       "> \n",
       "> \n",
       "> **Attenzione:**  anche settori tradizionali richiederanno professionisti con competenze aggiornate e digitali.  Un falegname che utilizza software di progettazione assistita da computer (CAD) sarà più competitivo rispetto a uno che non lo fa.\n",
       "> \n",
       "> In conclusione, il futuro del lavoro sarà caratterizzato da una crescente richiesta di competenze tecnologiche, scientifiche e di problem-solving, ma anche dalla necessità di competenze trasversali che consentono l'adattabilità e la collaborazione.  L'apprendimento continuo sarà fondamentale per navigare con successo in questo scenario in evoluzione.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "#response = model.generate_content(\"Quali saranno i lavori del futuro?\") # commento per non sprecare token\n",
    "#print(response.text)\n",
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured output (json):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ```json\n",
       "> [\n",
       ">   {\n",
       ">     \"recipe_name\": \"Chocolate Chip Cookies\",\n",
       ">     \"ingredients\": [\n",
       ">       \"1 cup (2 sticks) unsalted butter, softened\",\n",
       ">       \"1 cup granulated sugar\",\n",
       ">       \"1 cup packed brown sugar\",\n",
       ">       \"2 teaspoons pure vanilla extract\",\n",
       ">       \"2 large eggs\",\n",
       ">       \"3 cups all-purpose flour\",\n",
       ">       \"1 teaspoon baking soda\",\n",
       ">       \"1 teaspoon salt\",\n",
       ">       \"2 cups chocolate chips\"\n",
       ">     ]\n",
       ">   },\n",
       ">   {\n",
       ">     \"recipe_name\": \"Oatmeal Raisin Cookies\",\n",
       ">     \"ingredients\": [\n",
       ">       \"1 cup (2 sticks) unsalted butter, softened\",\n",
       ">       \"1 cup granulated sugar\",\n",
       ">       \"1 cup packed brown sugar\",\n",
       ">       \"2 large eggs\",\n",
       ">       \"1 teaspoon vanilla extract\",\n",
       ">       \"3 cups all-purpose flour\",\n",
       ">       \"1 teaspoon baking soda\",\n",
       ">       \"1 teaspoon ground cinnamon\",\n",
       ">       \"1/2 teaspoon salt\",\n",
       ">       \"3 cups rolled oats\",\n",
       ">       \"1 cup raisins\"\n",
       ">     ]\n",
       ">   },\n",
       ">   {\n",
       ">     \"recipe_name\": \"Peanut Butter Cookies\",\n",
       ">     \"ingredients\": [\n",
       ">       \"1 cup creamy peanut butter\",\n",
       ">       \"1 cup granulated sugar\",\n",
       ">       \"1 cup packed brown sugar\",\n",
       ">       \"2 large eggs\",\n",
       ">       \"1 teaspoon baking soda\",\n",
       ">       \"1/2 teaspoon salt\",\n",
       ">       \"1 cup all-purpose flour\"\n",
       ">     ]\n",
       ">   },\n",
       ">   {\n",
       ">     \"recipe_name\": \"Snickerdoodles\",\n",
       ">     \"ingredients\": [\n",
       ">       \"1 cup (2 sticks) unsalted butter, softened\",\n",
       ">       \"1 3/4 cups granulated sugar\",\n",
       ">       \"2 large eggs\",\n",
       ">       \"2 1/4 cups all-purpose flour\",\n",
       ">       \"2 teaspoons cream of tartar\",\n",
       ">       \"1 teaspoon baking soda\",\n",
       ">       \"1/2 teaspoon salt\",\n",
       ">       \"2 teaspoons ground cinnamon\"\n",
       ">     ]\n",
       ">   }\n",
       "> ]\n",
       "> ```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"List a few popular cookie recipes in JSON format.\n",
    "\n",
    "Use this JSON schema:\n",
    "\n",
    "Recipe = {'recipe_name': str, 'ingredients': list[str]}\n",
    "Return: list[Recipe]\"\"\"\n",
    "#result = model.generate_content(prompt)\n",
    "to_markdown(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sui nostri dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\n",
    "\n",
    "def run_prompt():\n",
    "  global prompt\n",
    "  prompt = f\"\"\"Valuta i candidati che ti propongo nel database: \n",
    "  {', '.join(df_candidates['Full_text'].astype(str).to_list())}\n",
    "\n",
    "  Rispetto alla posizione lavorativa definita in:\n",
    "  {', '.join(df_vacancy['Full_text'].astype(str).to_list())}\n",
    "\n",
    "  Il risultato deve essere un dizionario con il seguente schema JSON:\n",
    "  diz = {{\n",
    "    'vacancy': int, # ovvero l'id della vacancy\n",
    "    'candidates': {{\n",
    "      int: str  # Dove int è l'id del candidato e str è la valutazione tra \"Ok\", \"Forse\", \"No\"\n",
    "    }}\n",
    "  }}\n",
    "\n",
    "  Per ogni candidato, valuta l'affinità con la vacancy dando una valutazione tra \"Ok\", \"Forse\" e \"No\". Usa un criterio oggettivo basato sulle informazioni disponibili.\n",
    "\n",
    "  Restituisci solo il dizionario nel formato richiesto.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/gmoro.t1@gigroup.local/workarea/smart_matching_neural_similarity/gabri/brutal_results_SM/excel_results/BRASILE/\"\n",
    "file_path = folder_path+\"response_0.xlsx\"\n",
    "\n",
    "df_vacancy = pd.read_excel(file_path, sheet_name=0)\n",
    "df_candidates = pd.read_excel(file_path, sheet_name=1)\n",
    "\n",
    "df_vacancy[\"Full_text\"] = df_vacancy.apply(lambda row: \", \".join(f\"{col}: {row[col]}\" for col in df_vacancy.columns), axis=1)\n",
    "df_candidates[\"Full_text\"] = df_candidates.apply(lambda row: \", \".join(f\"{col}: {row[col]}\" for col in df_candidates.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ```json\n",
       "> {\n",
       ">   \"vacancy\": 6279,\n",
       ">   \"candidates\": {\n",
       ">     1065393: \"Ok\",\n",
       ">     1113335: \"Ok\",\n",
       ">     1664675: \"Forse\",\n",
       ">     1085777: \"Ok\",\n",
       ">     1113337: \"Forse\",\n",
       ">     1085425: \"Ok\",\n",
       ">     1065395: \"Ok\",\n",
       ">     1127733: \"Ok\",\n",
       ">     1398123: \"Forse\",\n",
       ">     1116653: \"Ok\",\n",
       ">     1656627: \"Ok\",\n",
       ">     1498553: \"Ok\",\n",
       ">     1648959: \"Ok\",\n",
       ">     1646811: \"Ok\",\n",
       ">     1138723: \"Ok\",\n",
       ">     1086385: \"Ok\",\n",
       ">     1356933: \"Ok\",\n",
       ">     1095207: \"Ok\",\n",
       ">     1493477: \"Forse\",\n",
       ">     1182473: \"Ok\",\n",
       ">     1582831: \"Forse\",\n",
       ">     1524161: \"No\",\n",
       ">     1202713: \"Forse\",\n",
       ">     1117769: \"Forse\",\n",
       ">     1145137: \"Ok\",\n",
       ">     1099299: \"No\",\n",
       ">     1674819: \"Ok\",\n",
       ">     1136935: \"Forse\",\n",
       ">     1077639: \"No\",\n",
       ">     1086367: \"Ok\",\n",
       ">     1085335: \"Ok\",\n",
       ">     1126721: \"Ok\",\n",
       ">     1387013: \"No\",\n",
       ">     783811: \"Ok\",\n",
       ">     1426613: \"Forse\",\n",
       ">     1617945: \"Forse\",\n",
       ">     1648665: \"Forse\",\n",
       ">     1399119: \"Ok\",\n",
       ">     1105285: \"Ok\",\n",
       ">     1095857: \"Ok\",\n",
       ">     1144129: \"Ok\",\n",
       ">     1698149: \"Forse\",\n",
       ">     1363535: \"Ok\",\n",
       ">     1668689: \"Ok\",\n",
       ">     1652877: \"Ok\",\n",
       ">     1369851: \"Ok\",\n",
       ">     1649985: \"Ok\",\n",
       ">     1300029: \"Forse\",\n",
       ">     1603463: \"No\",\n",
       ">     1033793: \"No\",\n",
       ">     1656873: \"Ok\",\n",
       ">     1657221: \"Forse\",\n",
       ">     1338865: \"Forse\",\n",
       ">     1394325: \"Ok\",\n",
       ">     1127225: \"Forse\",\n",
       ">     1127733: \"Ok\",\n",
       ">     1140049: \"Ok\",\n",
       ">     1100195: \"Ok\",\n",
       ">     1053955: \"No\",\n",
       ">     1388173: \"Forse\",\n",
       ">     1471659: \"Ok\",\n",
       ">     1635391: \"Ok\",\n",
       ">     1404027: \"Forse\",\n",
       ">     1658523: \"Forse\",\n",
       ">     1193689: \"Forse\",\n",
       ">     1119491: \"Forse\",\n",
       ">     1699285: \"Ok\",\n",
       ">     1400041: \"Ok\",\n",
       ">     1671461: \"Ok\",\n",
       ">     985013: \"Ok\",\n",
       ">     1359899: \"Forse\",\n",
       ">     1100953: \"Ok\",\n",
       ">     1638473: \"Ok\",\n",
       ">     1048767: \"No\",\n",
       ">     1081149: \"Ok\"\n",
       ">   }\n",
       "> }\n",
       "> ```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_prompt()\n",
    "result = model.generate_content(prompt)\n",
    "to_markdown(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/gmoro.t1@gigroup.local/workarea/smart_matching_neural_similarity/gabri/brutal_results_SM/excel_results/BRASILE/\"\n",
    "file_path = folder_path+\"response_2.xlsx\"\n",
    "\n",
    "df_vacancy = pd.read_excel(file_path, sheet_name=0)\n",
    "df_candidates = pd.read_excel(file_path, sheet_name=1)\n",
    "\n",
    "df_vacancy[\"Full_text\"] = df_vacancy.apply(lambda row: \", \".join(f\"{col}: {row[col]}\" for col in df_vacancy.columns), axis=1)\n",
    "df_candidates[\"Full_text\"] = df_candidates.apply(lambda row: \", \".join(f\"{col}: {row[col]}\" for col in df_candidates.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ```json\n",
       "> {\n",
       ">   \"vacancy\": 5301,\n",
       ">   \"candidates\": {\n",
       ">     1717205: \"Ok\",\n",
       ">     1637933: \"Ok\",\n",
       ">     1097497: \"Ok\",\n",
       ">     1551791: \"Forse\",\n",
       ">     1050853: \"Ok\",\n",
       ">     1079087: \"No\",\n",
       ">     1484729: \"Ok\",\n",
       ">     1092827: \"Ok\",\n",
       ">     1549417: \"Ok\",\n",
       ">     1122107: \"Forse\",\n",
       ">     1023155: \"Ok\",\n",
       ">     1047055: \"Ok\",\n",
       ">     1079081: \"Forse\",\n",
       ">     1091413: \"No\",\n",
       ">     894065: \"Ok\",\n",
       ">     1449937: \"Ok\",\n",
       ">     332433: \"Ok\",\n",
       ">     1515771: \"Ok\",\n",
       ">     1667961: \"Ok\",\n",
       ">     889471: \"Forse\",\n",
       ">     989623: \"Ok\",\n",
       ">     1583069: \"Ok\",\n",
       ">     1172101: \"No\",\n",
       ">     1129595: \"Forse\",\n",
       ">     1091493: \"Ok\",\n",
       ">     1033457: \"Ok\",\n",
       ">     1615525: \"Ok\",\n",
       ">     804943: \"Ok\",\n",
       ">     1556069: \"Ok\",\n",
       ">     1079083: \"No\",\n",
       ">     1453311: \"Ok\",\n",
       ">     18787: \"Ok\",\n",
       ">     1607361: \"Forse\",\n",
       ">     1660051: \"Ok\",\n",
       ">     1613161: \"Ok\",\n",
       ">     1672493: \"Ok\",\n",
       ">     1107735: \"Ok\",\n",
       ">     1094397: \"Ok\",\n",
       ">     1071499: \"No\",\n",
       ">     1079079: \"No\",\n",
       ">     457519: \"Ok\",\n",
       ">     1545871: \"Forse\",\n",
       ">     1607927: \"Forse\",\n",
       ">     1617371: \"Ok\",\n",
       ">     1133277: \"Ok\",\n",
       ">     1023651: \"Ok\",\n",
       ">     1094689: \"Ok\",\n",
       ">     1198827: \"No\",\n",
       ">     1097853: \"Ok\",\n",
       ">     1113623: \"Ok\",\n",
       ">     1481405: \"Ok\",\n",
       ">     1555179: \"Ok\",\n",
       ">     1139165: \"Ok\",\n",
       ">     1112975: \"Ok\",\n",
       ">     1620789: \"Ok\",\n",
       ">     1654269: \"Ok\",\n",
       ">     1608303: \"Ok\",\n",
       ">     999125: \"No\",\n",
       ">     1626507: \"Ok\",\n",
       ">     1092241: \"Ok\",\n",
       ">     1597129: \"Ok\",\n",
       ">     1596491: \"Ok\",\n",
       ">     1113931: \"Ok\",\n",
       ">     1608251: \"Ok\",\n",
       ">     1607927: \"Ok\",\n",
       ">     1563285: \"Ok\",\n",
       ">     1583061: \"Ok\",\n",
       ">     1625417: \"Ok\",\n",
       ">     1625741: \"Ok\",\n",
       ">     1110633: \"Ok\",\n",
       ">     1037443: \"Ok\",\n",
       ">     1097105: \"Ok\",\n",
       ">     892805: \"Ok\",\n",
       ">     1022843: \"Ok\",\n",
       ">     1572155: \"Ok\",\n",
       ">     1140203: \"Ok\",\n",
       ">     1608251: \"Ok\",\n",
       ">     1616253: \"Ok\",\n",
       ">     1613817: \"Ok\",\n",
       ">     1626783: \"Ok\",\n",
       ">     1120755: \"Ok\"\n",
       ">   }\n",
       "> }\n",
       "> ```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_prompt()\n",
    "result = model.generate_content(prompt)\n",
    "to_markdown(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/gmoro.t1@gigroup.local/workarea/smart_matching_neural_similarity/gabri/brutal_results_SM/excel_results/POLONIA/\"\n",
    "file_path = folder_path+\"response_192.xlsx\"\n",
    "\n",
    "df_vacancy = pd.read_excel(file_path, sheet_name=0)\n",
    "df_candidates = pd.read_excel(file_path, sheet_name=1)\n",
    "\n",
    "df_vacancy[\"Full_text\"] = df_vacancy.apply(lambda row: \", \".join(f\"{col}: {row[col]}\" for col in df_vacancy.columns), axis=1)\n",
    "df_candidates[\"Full_text\"] = df_candidates.apply(lambda row: \", \".join(f\"{col}: {row[col]}\" for col in df_candidates.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ```json\n",
       "> {\n",
       ">   \"vacancy\": 120977,\n",
       ">   \"candidates\": {\n",
       ">     996971: \"Forse\",\n",
       ">     1241759: \"No\",\n",
       ">     871967: \"No\",\n",
       ">     389355: \"Forse\",\n",
       ">     1030287: \"No\",\n",
       ">     1419139: \"Ok\",\n",
       ">     36199: \"Forse\",\n",
       ">     62785: \"Ok\",\n",
       ">     235891: \"Ok\",\n",
       ">     660783: \"Forse\",\n",
       ">     1150575: \"No\",\n",
       ">     1021331: \"Ok\",\n",
       ">     638641: \"No\",\n",
       ">     1411113: \"No\",\n",
       ">     1225057: \"Forse\",\n",
       ">     891811: \"Ok\",\n",
       ">     679051: \"Ok\",\n",
       ">     604080: \"Ok\",\n",
       ">     650379: \"No\",\n",
       ">     785105: \"No\",\n",
       ">     856179: \"Ok\",\n",
       ">     813707: \"Forse\",\n",
       ">     1349749: \"No\",\n",
       ">     1226639: \"Forse\",\n",
       ">     987281: \"Ok\",\n",
       ">     792331: \"Ok\",\n",
       ">     1401243: \"Ok\",\n",
       ">     1457987: \"Ok\",\n",
       ">     686497: \"Forse\",\n",
       ">     1114903: \"Ok\",\n",
       ">     1353893: \"No\",\n",
       ">     872499: \"Forse\",\n",
       ">     1641087: \"Ok\",\n",
       ">     673765: \"Ok\",\n",
       ">     996117: \"Ok\",\n",
       ">     1034261: \"Ok\",\n",
       ">     986583: \"Ok\",\n",
       ">     63357: \"Forse\",\n",
       ">     1134085: \"No\",\n",
       ">     947271: \"Forse\",\n",
       ">     1413195: \"Ok\",\n",
       ">     1217461: \"Ok\",\n",
       ">     1470675: \"Forse\",\n",
       ">     1014805: \"Ok\",\n",
       ">     1513791: \"Ok\",\n",
       ">     827145: \"Ok\",\n",
       ">     1245369: \"Ok\",\n",
       ">     1300967: \"Ok\",\n",
       ">     764341: \"Ok\",\n",
       ">     659103: \"Ok\",\n",
       ">     1137825: \"Ok\",\n",
       ">     970043: \"Ok\",\n",
       ">     1195155: \"Ok\",\n",
       ">     1381221: \"Ok\",\n",
       ">     1239733: \"Forse\",\n",
       ">     1091209: \"Ok\",\n",
       ">     1443223: \"Forse\",\n",
       ">     1137821: \"Ok\",\n",
       ">     508060: \"Ok\",\n",
       ">     960911: \"Ok\",\n",
       ">     65287: \"Ok\",\n",
       ">     1646989: \"Ok\",\n",
       ">     684633: \"Forse\",\n",
       ">     757307: \"Ok\",\n",
       ">     962795: \"Ok\",\n",
       ">     475975: \"No\",\n",
       ">     1641121: \"Ok\",\n",
       ">     1167337: \"Ok\",\n",
       ">     1268581: \"Ok\",\n",
       ">     652489: \"Ok\",\n",
       ">     1080699: \"No\",\n",
       ">     1005301: \"Forse\",\n",
       ">     962589: \"Ok\",\n",
       ">     1181511: \"Ok\",\n",
       ">     954369: \"Ok\",\n",
       ">     817713: \"Ok\",\n",
       ">     714861: \"Ok\",\n",
       ">     845901: \"Ok\",\n",
       ">     781579: \"Ok\",\n",
       ">     952145: \"Ok\",\n",
       ">     1038477: \"Forse\",\n",
       ">     997259: \"Forse\",\n",
       ">     820171: \"Ok\"\n",
       ">   }\n",
       "> }\n",
       "> ```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_prompt()\n",
    "result = model.generate_content(prompt)\n",
    "to_markdown(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/gmoro.t1@gigroup.local/workarea/smart_matching_neural_similarity/gabri/brutal_results_SM/excel_results/POLONIA/\"\n",
    "file_path = folder_path+\"response_186.xlsx\"\n",
    "\n",
    "df_vacancy = pd.read_excel(file_path, sheet_name=0)\n",
    "df_candidates = pd.read_excel(file_path, sheet_name=1)\n",
    "\n",
    "df_vacancy[\"Full_text\"] = df_vacancy.apply(lambda row: \", \".join(f\"{col}: {row[col]}\" for col in df_vacancy.columns), axis=1)\n",
    "df_candidates[\"Full_text\"] = df_candidates.apply(lambda row: \", \".join(f\"{col}: {row[col]}\" for col in df_candidates.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> ```json\n",
       "> {\n",
       ">   \"vacancy\": 78003,\n",
       ">   \"candidates\": {\n",
       ">     1247573: \"Ok\",\n",
       ">     192471: \"Forse\",\n",
       ">     147259: \"Ok\",\n",
       ">     670005: \"Ok\",\n",
       ">     771977: \"Ok\",\n",
       ">     1087909: \"Ok\",\n",
       ">     790861: \"Ok\",\n",
       ">     982103: \"Ok\",\n",
       ">     235657: \"Ok\",\n",
       ">     236971: \"Ok\",\n",
       ">     976771: \"Ok\",\n",
       ">     238545: \"Forse\",\n",
       ">     1188101: \"Ok\",\n",
       ">     1395903: \"Ok\",\n",
       ">     673553: \"Ok\",\n",
       ">     893415: \"Ok\",\n",
       ">     145263: \"Ok\",\n",
       ">     54707: \"Forse\",\n",
       ">     827585: \"Ok\",\n",
       ">     769993: \"Ok\",\n",
       ">     646729: \"Forse\",\n",
       ">     1260007: \"Ok\",\n",
       ">     1311045: \"Ok\",\n",
       ">     1343721: \"Ok\",\n",
       ">     1161969: \"Ok\",\n",
       ">     1389619: \"Ok\",\n",
       ">     1329773: \"Ok\",\n",
       ">     851923: \"Ok\",\n",
       ">     1468461: \"Ok\",\n",
       ">     1047153: \"Ok\",\n",
       ">     739357: \"Ok\",\n",
       ">     849053: \"Ok\",\n",
       ">     1053097: \"Forse\",\n",
       ">     822037: \"Ok\",\n",
       ">     1468009: \"Ok\",\n",
       ">     1045197: \"Ok\",\n",
       ">     891289: \"Forse\",\n",
       ">     650197: \"Ok\",\n",
       ">     590824: \"Ok\",\n",
       ">     667305: \"Ok\",\n",
       ">     1600079: \"Ok\",\n",
       ">     1340569: \"Ok\",\n",
       ">     975935: \"Ok\",\n",
       ">     687077: \"Ok\",\n",
       ">     1245747: \"Ok\",\n",
       ">     845063: \"Ok\",\n",
       ">     1244835: \"Ok\",\n",
       ">     1223005: \"Ok\",\n",
       ">     1168299: \"Ok\",\n",
       ">     1244497: \"Ok\",\n",
       ">     237819: \"Ok\",\n",
       ">     240835: \"Ok\",\n",
       ">     239095: \"Ok\",\n",
       ">     287363: \"Ok\",\n",
       ">     246293: \"Ok\",\n",
       ">     1287571: \"Ok\",\n",
       ">     1285383: \"Ok\",\n",
       ">     1270425: \"Ok\",\n",
       ">     855327: \"Ok\",\n",
       ">     1195647: \"Ok\",\n",
       ">     1168569: \"Ok\",\n",
       ">     896031: \"Ok\",\n",
       ">     1127701: \"Ok\",\n",
       ">     152059: \"Ok\",\n",
       ">     1351631: \"Ok\",\n",
       ">     830939: \"Ok\",\n",
       ">     1686385: \"Ok\",\n",
       ">     1362947: \"Ok\",\n",
       ">     265567: \"Ok\",\n",
       ">     1245999: \"Ok\",\n",
       ">     1688749: \"Ok\"\n",
       ">   }\n",
       "> }\n",
       "> ```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_prompt()\n",
    "result = model.generate_content(prompt)\n",
    "to_markdown(result.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart_matching_neural_similarity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
